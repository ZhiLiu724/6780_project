head(oscarsPP)
# no constant term: add -1 at the end
M <- mlogit(Ch~Nom+Dir+Aml+Afl+GG+PGA+Length+Days-1,data=D)
summary(M)
M1 <- mlogit(Ch~Nom+Dir+GG+PGA-1,data=D)
summary(M1)
#best case log-likelihood is 0
oscars <- read.csv("/Users/felicityj/Downloads/Analytics_Edge/week4/oscars.csv")
str(oscars)
oscars$Ch <- 2-oscars$Ch
# multinomial logistic regression
library(mlogit)
# input x: nomination for director and aml, pre-oscar awards for gg (indicator of golden globe) and pga, and length
oscars$GG <- oscars$Gdr + oscars$Gmc
oscarsPP <- subset(oscars, PP==1)
D <- mlogit.data(subset(oscarsPP, Year<=2006), choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch ~ Nom+Dir+GG+Aml+Afl+PGA+Days+Length-1, data = D)
summary(M)
M1 <- mlogit(Ch ~ Nom+Dir+GG+PGA-1, data = D, method = "nr", print.level=0)
summary(M1)
ACI_M = 2*4-2*(-36.772)
AIC_M = 2*4-2*(-36.772)
AIC_M
rho_M1 = 1-(-38.171)/(log(0.2)*56)
rho_M1
D1 <- mlogit.data(subset(oscarsPP, Year>2006), choice = "Ch", shape = "long", alt.var = "Mode")
D <- mlogit.data(subset(oscarsPP, Year), choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch ~ Nom+Dir+GG+Aml+Afl+PGA+Days+Length-1, data = D)
# surprising winner
D <- mlogit.data(oscarsPP, choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch ~ Nom+Dir+GG+Aml+Afl+PGA+Days+Length-1, data = D)
P <- predict(M, newdata = D)
P
M <- mlogit(Ch ~ Nom+Dir+GG+PGA-1, data = D)
P <- predict(M, newdata = D)
P
Pred$Prob <- as.vector(t(P))
Pred <- as.vector(t(P))
oscars$Pred <- Pred
oscarsPP$Pred <- Pred
subset(oscarsPP)
oscars <- read.csv("/Users/felicityj/Downloads/Analytics_Edge/week4/oscars.csv")
str(oscars)
oscars$Ch <- 2-oscars$Ch
subset(oscarsPP, Year==2004)
## best male actor
oscarsMM <- subset(oscars, MM==1)
Fail <0
Fail <- 0
Predict <- Null
Predict <- NULL
summary(oscarsMM)
Coefficients <- NULL
Fail <- 0
?as.logical
as.logical(1)
as.logical(0)
as.logical(3)
as.logical(-1)
# time series cross validation
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode"))
M <- mlogit(Ch~Pic+Gm1+Gm2+PrN1+PrW1-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode"))
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which(subset(oscarsMM, Year==i+1)$Ch))
}
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode"))
M <- mlogit(Ch~Pic+Gm1+Gm2+PrN1+PrW1-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode"))
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which(subset(oscarsMM, Year==i+1)$Ch))
}
# time series cross validation
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode"))
M <- mlogit(Ch~Pic+Gm1+Gm2+PrN1+PrW1-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode"))
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which(subset(oscarsMM, Year==i+1)$Ch))
}
# time series cross validation
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch~Pic+Gm1+Gm2+PrN1+PrW1-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode")
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which(subset(oscarsMM, Year==i+1)$Ch))
}
# time series cross validation
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch~Pic+Gm1+Gm2+PrN1+PrNl-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode")
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which(subset(oscarsMM, Year==i+1)$Ch))
}
# time series cross validation
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch~Pic+Gm1+Gm2+PrNl+PrWl-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode")
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which(subset(oscarsMM, Year==i+1)$Ch))
}
# time series cross validation
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch~Pic+Gm1+Gm2+PrNl+PrWl-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode")
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which.max(subset(oscarsMM, Year==i+1)$Ch))
}
Coefficients
summary(M)
oscars <- read.csv("/Users/felicityj/Downloads/Analytics_Edge/week4/oscars.csv")
str(oscars)
oscars$Ch <- 2-oscars$Ch
oscarsMM <- subset(oscars, MM==1)
Fail <- 0
Predict <- NULL
Coefficients <- NULL
summary(oscarsMM)
# time series cross validation
for(i in 1960:2006){
D <- mlogit.data(subset(oscarsMM, Year<=i), choice = "Ch", shape = "long", alt.var = "Mode")
M <- mlogit(Ch~Pic+Gm1+Gm2+PrNl+PrWl-1, data = D)
Coefficients <- rbind(Coefficients, M$coefficients)
D1 <- mlogit.data(subset(oscarsMM, Year==i+1), choice = "Ch", shape = "long", alt.var = "Mode")
P1 <- predict(M, newdata = D1)
Predict <- rbind(Predict, P1)
Fail <- Fail+as.logical(which.max(P1)-which.max(subset(oscarsMM, Year==i+1)$Ch))
}
Coefficients
1:263
sample(1:263, 131)
sample(1:263, 131)
sample(1:263, 131)
set.seed(1)
sample(1:263, 131)
sample(1:263, 131)
set.seed(1)
sample(1:263, 131)
install.packages('Julia')
l2 <- matrix(0, 500, 1)
# for (j in 1:500){
#   l2[j] <- j*(1/j)**2
# }
for (j in 1:500){
p = runif(j)
l2[j] <-sum((p/sum(p))**2)-1/j
}
df <- data.frame(stock_num = c(1:500), l2_norm = l2)
df
View(df)
View(df)
View(df)
d <- c(1:10)
d[c(T,T,F)]
?cv.glm
library(tibble)
library(dplyr)
library(boot)
library(ISLR)
library(glmnet)
library(leaps)
# preproc
df <- as_tibble(na.omit(Hitters))
model.pre <- lm(Salary~., df)
pre.summ <- summary(model.pre)
outliers <- abs(rstudent(model.pre)) > 3
df.post <- df[!outliers,]
model.post <- lm(Salary~., df.post)
post.summ <- summary(model.post)
# print
print(pre.summ$adj.r.squared)
print(post.summ$adj.r.squared)
# try no intercept model
model.noint <- lm(Salary~. + 0, df.post)
noint.summ <- summary(model.noint)
print(noint.summ$adj.r.squared)
# best subset selection, no intercept
regfit.full <- regsubsets(Salary~., data=df.post, nvmax=19, intercept=F)
reg.summary <- summary(regfit.full)
# get best 5-predictor subset
best_5 <- reg.summary$which[5,]
print(best_5[best_5])
# print Cp, BIC, R^2
pdf("cp.pdf")
plot(reg.summary$cp, xlab="p", ylab=expression(C[p]), type="b")
dev.off()
pdf("bic.pdf")
plot(reg.summary$bic, xlab="p", ylab="BIC", type="b")
dev.off()
pdf("adj_r2.pdf")
plot(reg.summary$adjr2, xlab="p", ylab=expression(R^2), type="b")
dev.off()
# define predict
predict.regsubsets <- function(regfit, newdata, id) {
mat <- model.matrix(formula(Salary~. + 0), newdata)
coefi <- coef(regfit, id=id)
xvars <- names(coefi)
as.matrix(mat[, xvars]) %*% coefi
}
# cross validation function for convenience
cv_fn <- function(folds, fold_id, method="exhaustive") {
cv.error <- rep(0, 19)
best.fit <- regsubsets(Salary~., data=df.post[folds != fold_id,],
nvmax=19, intercept=F, method=method)
for (i in (1:19)) {
pred <- predict(best.fit, df.post[folds == fold_id,], id=i)
cv.error[i] <- mean((df.post$Salary[folds == fold_id] - pred)^2)
}
return( cv.error )
}
# run cv for K = {5, 10}
for (method in c("forward", "backward")) {
for (k in c(5, 10)) {
set.seed(1)
folds <- sample(1:k, nrow(df.post), replace=TRUE)
cv.errors <- sapply(1:k, cv_fn, folds=folds, method=method)  # 19xk matrix of errors
cv.errors <- apply(cv.errors, 1, mean)  # average over rows
pdf(paste("cv_errors_", method, "_", k, ".pdf", sep=""))
plot(cv.errors, type="b", xlab="p", ylab="Validation MSE")
dev.off()
}
}
# LASSO with cross-validation
# generate data
n <- 500
d <- 600
X <- matrix(rnorm(n * d), ncol=d)
beta <- runif(d)
beta[1:(d / 2)] <- 0  # zero out
y <- X %*% beta + rnorm(n)
train_ind <- c(1:(3 * n / 5))
X.train <- X[train_ind,]
X.test <- X[-train_ind,]
y.train <- y[train_ind]
y.test <- y[-train_ind]
# LASSO
lasso.mod <- glmnet(X.train, y.train, alpha=1)
cv.out <- cv.glmnet(X.train, y.train, alpha=1, nfolds=10)
lbest <- cv.out$lambda.min
lasso.pred <- predict(lasso.mod, s=lbest, newx=X.test)
lasso.mse <- mean((lasso.pred - y.test)^2)
print(paste("LASSO MSE: ", lasso.mse))
pdf("lasso_cv_mse.pdf")
plot(cv.out)
dev.off()
# part 2
x <- model.matrix(Salary~., df.post)[,-1]
y <- df.post$Salary
grid <- 10^seq(10, -2, length=100)
ridge.mod <- glmnet(x, y, alpha=0, lambda=grid, intercept=FALSE)
l2norm <- sqrt(apply(ridge.mod$beta^2, 2, sum))
pdf("ridge_l2.pdf")
plot(log(grid), l2norm)
dev.off()
# split
set.seed(1)
train <- sample(1:nrow(x), nrow(x) / 2)
y.train <- y[train]
y.test <- y[-train]
# model fit on the training set
# ridge.mod <- glmnet(x[train,], y.train, alpha=0, lambda=grid, intercept=FALSE)
ridge.mod <- glmnet(x[train,], y.train, alpha=0, nlambda=20, intercept=FALSE)
# cv.ridge <- cv.glmnet(x[train,], y.train, lambda=grid, alpha=0, intercept=FALSE)
cv.ridge <- cv.glmnet(x[train,], y.train, nlambda=20, alpha=0, intercept=FALSE)
lbest <- cv.ridge$lambda.min
library(tibble)
library(dplyr)
library(boot)
library(ISLR)
library(glmnet)
install.packages(ISLR)
install.packages(glmnet)
install.packages("ISLR"")
remove.packages("rstan")
if (file.exists(".RData")) file.remove(".RData")
Sys.setenv(DOWNLOAD_STATIC_LIBV8 = 1) # only necessary for Linux without the nodejs library / headers
install.packages("rstan", repos = "https://cloud.r-project.org/", dependencies = TRUE)
example(stan_model, package = "rstan", run.dontrun = TRUE)
install.packages("gam")
knitr::opts_chunk$set(echo = TRUE)
library(rstan)
library(brms)
library(dplyr)
```{r load libraries, echo = FALSE}
library(rstan)
library(brms)
library(dplyr)
library(rstan)
library(brms)
library(dplyr)
install.packages("brms")
data = data.frame(read.csv(path))
path = "/Users/felicityj/Documents/GitHub/6780_project/data.csv"
data = data.frame(read.csv(path))
data = data.frame(read.csv(path))
data_with_ct <- data[!is.na(data['census_tract']),]
dim(data); dim(data_with_ct)
schools_data <- list(
J = 8,
y = c(28,  8, -3,  7, -1,  1, 18, 12),
sigma = c(15, 10, 16, 11,  9, 11, 10, 18)
)
fit1 <- stan(
file = "spatial.stan",  # Stan program
data = schools_data,    # named list of data
chains = 4,             # number of Markov chains
warmup = 1000,          # number of warmup iterations per chain
iter = 2000,            # total number of iterations per chain
cores = 1,              # number of cores (could use one per chain)
refresh = 0             # no progress shown
)
fit1 <- stan(
file = "spatial.stan",  # Stan program
data = schools_data,    # named list of data
chains = 4,             # number of Markov chains
warmup = 1000,          # number of warmup iterations per chain
iter = 2000,            # total number of iterations per chain
cores = 1,              # number of cores (could use one per chain)
refresh = 0)             # no progress shown
setwd("~/Documents/GitHub/6780_project")
fit1 <- stan(
file = "spatial.stan",  # Stan program
data = schools_data,    # named list of data
chains = 4,             # number of Markov chains
warmup = 1000,          # number of warmup iterations per chain
iter = 2000,            # total number of iterations per chain
cores = 1,              # number of cores (could use one per chain)
refresh = 0)             # no progress shown
```{r}
print("a")
print(fit1, pars=c("theta", "mu", "tau", "lp__"), probs=c(.1,.5,.9))
View(data_with_ct)
head(data_with_ct)
path = "/Users/felicityj/Documents/GitHub/6780_project/data_with_coordinates.csv"
data = data.frame(read.csv(path))
data = data.frame(read.csv(path))
data_with_ct <- data[!is.na(data['census_tract']),]
dim(data); dim(data_with_ct)
head(data_with_ct)
x <- array(rnorm(n=200),dim=c(100,2))
x
install.packages("rjags")
install.packages("MASS")
install.packages("MCMCpack")
library(rjags)library(MASS)  # need for mvrnormlibrary(MCMCpack) # need for rwish
library(MASS)  # need for mvrnormlibrary(MCMCpack) # need for rwish
library(rstan)
library(brms)
library(brms)
library(dplyr)
library(rjags)
install.packages("rjags")
library(rjags)
library(rjags)
set.seed(6780)N = 15000S = matrix(c(1,.2,.2,5),nrow=2)y = mvrnorm(N,c(1,3),S)
set.seed(6780)
N = 15000
S = matrix(c(1,.2,.2,5),nrow=2)
y = mvrnorm(N,c(1,3),S)
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/3/rjags_3-2.tar.gz",
args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'
"
)
install.packages("devtools")
library(devtools)
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/3/rjags_3-2.tar.gz",
args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'
"
)
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/4/rjags_4-4.tar.gz",
args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'
"
)
devtools::install_url("http://sourceforge.net/projects/mcmc-jags/files/rjags/4/rjags_4-4.tar.gz",
args="--configure-args='--with-jags-include=/Users/casallas/homebrew/opt/jags/include/JAGS
--with-jags-lib=/Users/casallas/homebrew/opt/jags/lib'
"
)
install.packages("rjags")
library(rjags)
y
model{for(i in 1:N){
model{
mu0 = as.vector(c(0,0))
S2 = matrix(c(1,0,0,1),nrow=2)/1000
S3 =  matrix(c(1,0,0,1),nrow=2)/10000
data = list(y=y,N=N,S2=S2,S3=S3,mu0=mu0)
inits=function(){list( mu=mvrnorm(1,mu0,matrix(c(10,0,0,10),nrow=2) ),
tau = rwish(3,matrix(c(.02,0,0,.04),nrow=2)) )}
mu0 = as.vector(c(0,0))
S2 = matrix(c(1,0,0,1),nrow=2)/1000
S3 =  matrix(c(1,0,0,1),nrow=2)/10000
data = list(y=y,N=N,S2=S2,S3=S3,mu0=mu0)
inits=function(){list( mu=mvrnorm(1,mu0,matrix(c(10,0,0,10),nrow=2) ),
tau = rwish(3,matrix(c(.02,0,0,.04),nrow=2)) )}
y
t1 = proc.time()
multNorm.mcmc <- jags.model("mult_normal.bug",data=data, inits = inits,n.chains = 3, n.adapt=1000, quiet=FALSE)
multNorm.mcmc <- jags.model("spatial",data=data, inits = inits,n.chains = 3, n.adapt=1000, quiet=FALSE)
multNorm.mcmc <- jags.model("spatial.bug",data=data, inits = inits,n.chains = 3, n.adapt=1000, quiet=FALSE)
library(MCMCpack) # need for rwish
multNorm.mcmc <- jags.model("spatial.bug",data=data, inits = inits,n.chains = 3, n.adapt=1000, quiet=FALSE)
nthin = 5
multNorm.coda = coda.samples(multNorm.mcmc,c("mu","cov[1,1]","cov[1,2]","cov[2,2]","corr"),500*nthin, thin = nthin)
multNorm.coda = coda.samples(multNorm.mcmc,c("mu","cov[1,1]","cov[1,2]","cov[2,2]","corr"),500*nthin, thin = nthin)
t2 = proc.time()
t2-t1
summary(multNorm.coda,digits=2)
gelman.diag(multNorm.coda)
effectiveSize(multNorm.coda)
par(mfrow = c(3, 4))
plot(multNorm.coda, auto.layout = FALSE)
plot(multNorm.coda, auto.layout = FALSE)
par(mfrow=c(2,3))
typeof(y)
## bivariate normal on simulated data
colnames(data_with_ct)
coord = c(data_with_ct$Latitude, data_with_ct$Longitude)
coord
coord = [data_with_ct$Latitude, data_with_ct$Longitude]
coord = data.matrix(data_with_ct$Latitude, data_with_ct$Longitude)
coord
View(coord)
typeof(coord)
coord = subset(data_with_ct, select=c("Latitude", "Longitude"))
coord
View(coord)
coord = data.matrix(coord)
typeof(coord)
dim(coord)
N = dim(coord)[1]
N
mu0 = as.vector(c(0,0))
S2 = matrix(c(1,0,0,1),nrow=2)/1000
S3 =  matrix(c(1,0,0,1),nrow=2)/10000
data = list(y=y,N=N,S2=S2,S3=S3,mu0=mu0)
inits=function(){list( mu=mvrnorm(1,mu0,matrix(c(10,0,0,10),nrow=2) ),
tau = rwish(3,matrix(c(.02,0,0,.04),nrow=2)) )}
mu0 = as.vector(c(0,0))
S2 = matrix(c(1,0,0,1),nrow=2)/1000
S3 =  matrix(c(1,0,0,1),nrow=2)/10000
data = list(y=y,N=N,S2=S2,S3=S3,mu0=mu0)
inits=function(){list( mu=mvrnorm(1,mu0,matrix(c(10,0,0,10),nrow=2) ),
tau = rwish(3,matrix(c(.02,0,0,.04),nrow=2)) )}
```{r}
t1 = proc.time()
multNorm.mcmc <- jags.model("spatial.bug",data=coord, inits = inits,n.chains = 3, n.adapt=1000, quiet=FALSE)
data = list(y=coord,N=N,S2=S2,S3=S3,mu0=mu0)
inits=function(){list( mu=mvrnorm(1,mu0,matrix(c(10,0,0,10),nrow=2) ),
tau = rwish(3,matrix(c(.02,0,0,.04),nrow=2)) )}
mu0 = as.vector(c(0,0))
S2 = matrix(c(1,0,0,1),nrow=2)/1000
S3 =  matrix(c(1,0,0,1),nrow=2)/10000
data = list(y=coord,N=N,S2=S2,S3=S3,mu0=mu0)
inits=function(){list( mu=mvrnorm(1,mu0,matrix(c(10,0,0,10),nrow=2) ),
tau = rwish(3,matrix(c(.02,0,0,.04),nrow=2)) )}
```{r}
t1 = proc.time()
multNorm.mcmc <- jags.model("spatial.bug",data=coord, inits = inits,n.chains = 3, n.adapt=1000, quiet=FALSE)
multNorm.mcmc <- jags.model("spatial.bug",data=data, inits = inits,n.chains = 3, n.adapt=1000, quiet=FALSE)
nthin = 5
multNorm.coda = coda.samples(multNorm.mcmc,c("mu","cov[1,1]","cov[1,2]","cov[2,2]","corr"),500*nthin, thin = nthin)
multNorm.coda = coda.samples(multNorm.mcmc,c("mu","cov[1,1]","cov[1,2]","cov[2,2]","corr"),500*nthin, thin = nthin)
t2 = proc.time()
t2-t1
summary(multNorm.coda,digits=2)
summary(multNorm.coda,digits=2)
t2-t1
summary(multNorm.coda,digits=2)
gelman.diag(multNorm.coda)
effectiveSize(multNorm.coda)
par(mfrow = c(3, 4))
plot(multNorm.coda, auto.layout = FALSE)
par(mfrow=c(2,3))
gelman.plot(multNorm.coda,auto.layout = FALSE)
apply(coord, 2, median)
xi = as.vector(apply(coord, 2, median))
xi
apply(coord, 2, range)
a=apply(coord, 2, range)
a[2]-a[1]
a[2,1]-a[1,1]
a[2,2]-a[1,2]
xi = as.vector(apply(coord, 2, median))
rng_coord = apply(coord, 2, range)
R1 = rng_coord[2,1]-rng_coord[1,1]
R2 = rng_coord[2,2]-rng_coord[1,2]
kappa = matrix(c(R1^2,0,0,R2^2),nrow=2)/1000
kappa
